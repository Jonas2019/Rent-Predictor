{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from re import search\n",
    "from time import sleep\n",
    "import random\n",
    "\n",
    "\n",
    "startingUrl = \"https://vancouver.craigslist.org/search/apa?query=ubc&min_price=&max_price=&availabilityMode=0&sale_date=all+dates\"\n",
    "# add 's=START_NUMBER' to the query in order to scrape through paginator\n",
    "\n",
    "# try to avoid scraper defense\n",
    "HEADER = {\n",
    "    'Access-Control-Allow-Origin': '*',\n",
    "    'Access-Control-Allow-Methods': 'GET',\n",
    "    'Access-Control-Allow-Headers': 'Content-Type',\n",
    "    'Access-Control-Max-Age': '3600',\n",
    "    'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:52.0) Gecko/20100101 Firefox/52.0'\n",
    "    }\n",
    "req = requests.get(startingUrl, HEADER)\n",
    "soup = BeautifulSoup(req.content, 'html.parser')\n",
    "# find all rows\n",
    "resultRows = soup.find_all(\"li\", {\"class\": \"result-row\"})\n",
    "\n",
    "data = []\n",
    "for result in resultRows:\n",
    "    row = {}\n",
    "    time = result.find(\"time\", {\"class\": \"result-date\"})['datetime']\n",
    "    header = result.find(\"h3\", {\"class\": \"result-heading\"}).find(\"a\")\n",
    "    name = header.text\n",
    "    href = header['href']\n",
    "    price = result.find(\"span\", {\"class\": \"result-price\"}).text\n",
    "    bdr = result.find(\"span\", {\"class\": \"housing\"})\n",
    "    if bdr:\n",
    "        bdr = bdr.text\n",
    "        if search(\"br\", bdr):\n",
    "            bdr = int(bdr[bdr.find(' ')+len(' '):bdr.rfind('br')])\n",
    "        else:\n",
    "            bdr = 1\n",
    "    else:\n",
    "        bdr = 1\n",
    "    # put everything together\n",
    "    row['name'] = name\n",
    "    row['href'] = href\n",
    "    row['time'] = time\n",
    "    row['price'] = price\n",
    "    row['bedroom'] = bdr\n",
    "    data.append(row)\n",
    "# Put everything together in a dataframe\n",
    "df = pd.DataFrame(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pagination Handler\n",
    "totalCounts = int(soup.find(\"span\", {\"class\" : \"totalcount\"}).text)\n",
    "totalCounts\n",
    "def getPaginatorParameter(df, totalCounts):\n",
    "    result = []\n",
    "    temp = len(df)\n",
    "    one_iter = len(df)\n",
    "    while temp < totalCounts:\n",
    "        result.append(temp)\n",
    "        temp += one_iter\n",
    "    return result\n",
    "parameters = getPaginatorParameter(df, totalCounts)\n",
    "\n",
    "\n",
    "\n",
    "for param in parameters:\n",
    "    link = startingUrl + '&s=' + str(param)\n",
    "    req = requests.get(link, HEADER)\n",
    "    soup = BeautifulSoup(req.content, 'html.parser')\n",
    "# find all rows\n",
    "    resultRows = soup.find_all(\"li\", {\"class\": \"result-row\"})\n",
    "    tempData = []\n",
    "    for result in resultRows:\n",
    "        row = {}\n",
    "        time = result.find(\"time\", {\"class\": \"result-date\"})['datetime']\n",
    "        header = result.find(\"h3\", {\"class\": \"result-heading\"}).find(\"a\")\n",
    "        name = header.text\n",
    "        href = header['href']\n",
    "        price = result.find(\"span\", {\"class\": \"result-price\"}).text\n",
    "        bdr = result.find(\"span\", {\"class\": \"housing\"})\n",
    "        if bdr:\n",
    "            bdr = bdr.text\n",
    "            if search(\"br\", bdr):\n",
    "                bdr = int(bdr[bdr.find(' ')+len(' '):bdr.rfind('br')])\n",
    "            else:\n",
    "                bdr = 1\n",
    "        else:\n",
    "            bdr = 1\n",
    "        # put everything together\n",
    "        row['name'] = name\n",
    "        row['href'] = href\n",
    "        row['time'] = time\n",
    "        row['price'] = price\n",
    "        row['bedroom'] = bdr\n",
    "        tempData.append(row)\n",
    "    # Put everything together in a dataframe\n",
    "    tempDf = pd.DataFrame(tempData)\n",
    "    df = df.append(tempDf, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Message the data\n",
    "# Convert string to datetime\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "# Currency\n",
    "df['price'] = df['price'].apply(lambda x: x.replace('$','')).apply(lambda x: x.replace(',','')).astype(np.int64)\n",
    "\n",
    "df.drop(df.loc[df['price']==0].index, inplace=True)\n",
    "df = df.drop_duplicates(subset=['name','price','bedroom'], keep='first')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location = []\n",
    "# for link in df['href']:\n",
    "#     req = requests.get(link, HEADER)\n",
    "#     print(link)\n",
    "#     soup = BeautifulSoup(req.content, 'html.parser')\n",
    "#     result = soup.find(\"div\", {\"class\": \"mapaddress\"})\n",
    "#     # If listing does specifies map address\n",
    "#     if result.text:\n",
    "#         location.append(result.text)\n",
    "#     # If listing does not specify map address\n",
    "#     else:\n",
    "#         location.append('location not found')\n",
    "\n",
    "hrefs = df['href'].tolist()\n",
    "location = []\n",
    "for index in range(0,len(hrefs)):\n",
    "    req = requests.get(hrefs[index], headers={'User-Agent': 'Custom'})\n",
    "    \n",
    "    sleep(random.randint(3, 7))\n",
    "    print(\"currently on row {}\".format(index + 1))\n",
    "    if req.status_code == 200:\n",
    "        soup = BeautifulSoup(req.content, 'html.parser')\n",
    "        result = soup.find(\"div\", {\"class\": \"mapaddress\"})\n",
    "        # If listing does specifies map address\n",
    "        if result is not None:\n",
    "            location.append(result.text)\n",
    "        # If listing does not specify map address\n",
    "        else:\n",
    "            location.append('location not found')\n",
    "    else:\n",
    "        print(\"unexpected status code {}\".format(req.status_code))\n",
    "        break\n",
    "location\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['location'] = location\n",
    "df.to_csv('data_frame.csv', index = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cca52fc7307b10f86a328227fc7248c1673620ae061c3daae191153de5778a67"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
